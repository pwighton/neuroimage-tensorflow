{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Install Nibable\n",
    "    - In Jupyter homescreen, click New->Terminal \n",
    "    - run `pip install nibabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import os, sys, re, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Helper functions for genTFrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Due to issue reading large .tfrecord files\n",
    "DEBUG_CROP=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def select_hipp(x):\n",
    "\tx[x != 17] = 0\n",
    "\tx[x == 17] = 1\n",
    "\treturn x\n",
    "\n",
    "def crop_brain(x):\n",
    "\tx = x[90:130,90:130,90:130] #should take volume zoomed in on hippocampus area\n",
    "\treturn x\n",
    "\n",
    "def preproc_brain(x):\n",
    "\tx = select_hipp(x)\n",
    "\tif DEBUG_CROP:\n",
    "\t\tx = crop_brain(x)   \n",
    "\treturn x\n",
    "\n",
    "def listfiles(folder):\n",
    "\tfor root, folders, files in os.walk(folder):\n",
    "\t\tfor filename in folders + files:\n",
    "\t\t\tyield os.path.join(root, filename)\n",
    "\n",
    "def gen_filename_pairs(data_dir, v_re, l_re):\n",
    "\tunfiltered_filelist=list(listfiles(data_dir))\n",
    "\tinput_list = [item for item in unfiltered_filelist if re.search(v_re,item)]\n",
    "\tlabel_list = [item for item in unfiltered_filelist if re.search(l_re,item)]\n",
    "\tprint(\"input_list size:    \", len(input_list))\n",
    "\tprint(\"label_list size:    \", len(label_list))\n",
    "\tif len(input_list) != len(label_list):\n",
    "\t\tprint(\"input_list size and label_list size don't match\")\n",
    "\t\traise Exception\n",
    "\treturn zip(input_list, label_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate a vol/label training set list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_list size:    ', 2)\n",
      "('label_list size:    ', 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/notebooks/data/buckner40/train/004/norm.nii.gz',\n",
       "  '/notebooks/data/buckner40/train/004/aseg.nii.gz'),\n",
       " ('/notebooks/data/buckner40/train/008/norm.nii.gz',\n",
       "  '/notebooks/data/buckner40/train/008/aseg.nii.gz')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_pairs = gen_filename_pairs('/notebooks/data/buckner40/train', 'norm', 'aseg')\n",
    "filename_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Helper functions for writing .tfrecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate the file `b40train.tfrecord` \n",
    "\n",
    "I guess the biggest lesson learned is tfrecords are a waste of time.  As your data set grows (as it should if you're using neural-nets) they become unweidy.  They can't encode the properties of the data (like input dimensions) and we were getting errors when training before we cropped the data.  You need to write a decoder for your data with tfrecords anyway.  So you might as just feed directly and skip all this encoding nonesense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:\n",
      "('  volume: ', '/notebooks/data/buckner40/train/004/norm.nii.gz')\n",
      "('  label:  ', '/notebooks/data/buckner40/train/004/aseg.nii.gz')\n",
      "DIMS: 404040\n",
      "Processing:\n",
      "('  volume: ', '/notebooks/data/buckner40/train/008/norm.nii.gz')\n",
      "('  label:  ', '/notebooks/data/buckner40/train/008/aseg.nii.gz')\n",
      "DIMS: 404040\n"
     ]
    }
   ],
   "source": [
    "outfile = '/notebooks/data/b40train.tfrecord'\n",
    "writer = tf.python_io.TFRecordWriter(outfile)\n",
    "for v_filename, l_filename in filename_pairs:\n",
    "\n",
    "\tprint(\"Processing:\")\n",
    "\tprint(\"  volume: \", v_filename)\n",
    "\tprint(\"  label:  \", l_filename)\t\n",
    "\n",
    "\t# The volume, in nifti format\t\n",
    "\tv_nii = nib.load(v_filename)\n",
    "\t# The volume, in numpy format\n",
    "\tv_np = v_nii.get_data().astype('int16')\n",
    "\t# Crop because of .tfrecord issue\n",
    "\tif DEBUG_CROP:\n",
    "\t\tv_np = crop_brain(v_np)\n",
    "\t# The volume, in raw string format\n",
    "\tv_raw = v_np.tostring()\n",
    "\n",
    "\t# The label, in nifti format\n",
    "\tl_nii = nib.load(l_filename)\n",
    "\t# The label, in numpy format\n",
    "\tl_np = l_nii.get_data().astype('int16')\n",
    "\t# Preprocess the volume\n",
    "\tl_np = preproc_brain(l_np)\n",
    "\t# The label, in raw string format\n",
    "\tl_raw = l_np.tostring()\n",
    "\n",
    "\t# Dimensions\n",
    "\tx_dim = v_np.shape[0]\n",
    "\ty_dim = v_np.shape[1]\n",
    "\tz_dim = v_np.shape[2]\n",
    "\tprint(\"DIMS: \" + str(x_dim) + str(y_dim) + str(z_dim))\n",
    "\n",
    "\t# Put in the original images into array for future check for correctness\n",
    "\t# Uncomment to test (this is a memory hog)\n",
    "\t########################################\n",
    "\t# original_images.append((v_np, l_np))\n",
    "\n",
    "\tdata_point = tf.train.Example(features=tf.train.Features(feature={\n",
    "\t\t'image_raw': _bytes_feature(v_raw),\n",
    "\t\t'label_raw': _bytes_feature(l_raw)}))\n",
    "    \n",
    "\twriter.write(data_point.SerializeToString())\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Navigate through your jupyter filetree.\n",
    "There should be a data/b40train.tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Some model and training constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR='/notebooks/data'\n",
    "CHECKPOINT_DIR='/notebooks/tensorboard-data'\n",
    "TRAIN_FILE='b40-train.tfrecords'\n",
    "VALIDATION_FILE=''\n",
    "IMG_DIM=40\n",
    "NUM_CLASSES=2\n",
    "BATCH_SIZE=2\n",
    "NUM_EPOCHS=2\n",
    "DECAY_STEPS=1.0\n",
    "DECAY_RATE=1.0\n",
    "LEARNING_RATE=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pull a record out of tfrecord\n",
    "\n",
    "For 3D convolution, Tensorflow expects tensors in the shape\n",
    "```\n",
    "[Batch, X, Y, Z, Channel]\n",
    "```\n",
    "Here we return a single image/label tensor pair in the shape\n",
    "  - `[X, Y, Z, Channel]` for the image\n",
    "  - `[X, Y, Z]` for the label\n",
    "  \n",
    "Image is returned as float32 (conv3d will complain if it's an int)\n",
    "\n",
    "Here's a  good place to zero-center your data and do other nice things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "\treader = tf.TFRecordReader()\n",
    "\t_, serialized_example = reader.read(filename_queue)\n",
    "\tfeatures = tf.parse_single_example(serialized_example,features={\n",
    "\t\t'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "\t\t'label_raw': tf.FixedLenFeature([], tf.string)})\n",
    "\timage  = tf.cast(tf.decode_raw(features['image_raw'], tf.int16), tf.float32)\n",
    "\tlabels = tf.decode_raw(features['label_raw'], tf.int16)\n",
    "\t\n",
    "\t#PW 2017/03/03: Zero-center data here?\n",
    "\timage.set_shape([IMG_DIM*IMG_DIM*IMG_DIM])\n",
    "\timage  = tf.reshape(image, [IMG_DIM,IMG_DIM,IMG_DIM,1])\n",
    "\t\n",
    "\tlabels.set_shape([IMG_DIM*IMG_DIM*IMG_DIM])\n",
    "\tlabels  = tf.reshape(image, [IMG_DIM,IMG_DIM,IMG_DIM])\n",
    "\t\n",
    "\t# Dimensions (X, Y, Z, channles)\n",
    "\treturn image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate a training batch\n",
    "\t\"\"\"\n",
    "\t\tReads input data num_epochs times.\n",
    "\t\tArgs:\n",
    "\t\t\ttrain: Selects between the training (True) and validation (False) data.\n",
    "\t\t\tbatch_size: Number of examples per returned batch.\n",
    "\t\t\tnum_epochs: Number of times to read the input data, or 0/None to train forever.\n",
    "\t\tReturns:\n",
    "\t\t\tA tuple (images, labels), where:\n",
    "\t\t\t\t* images is a float tensor with shape [batch_size, DIM, DIM, DIM, 1]\n",
    "\t\t\t\t* labels is an int32 tensor with shape [batch_size, DIM, DIM, DIM] with the true label\n",
    "\t\t\tNote that an tf.train.QueueRunner is added to the graph, which\n",
    "\t\t\tmust be run using e.g. tf.train.start_queue_runners().\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def inputs(train, batch_size, num_epochs, filename):\n",
    "\n",
    "\tif not num_epochs: num_epochs = None\n",
    "\t\n",
    "\twith tf.name_scope('input'): \n",
    "\t\tfilename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "\t\n",
    "\t# Even when reading in multiple threads, share the filename queue.\n",
    "\timage, label = read_and_decode(filename_queue)\n",
    "\t\n",
    "\t# Shuffle the examples and collect them into batch_size batches.\n",
    "\t# (Internally uses a RandomShuffleQueue.)\n",
    "\t# We run this in two threads to avoid being a bottleneck.\n",
    "\timages, sparse_labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, num_threads=2,capacity=1000 + 3 * batch_size,min_after_dequeue=1000)\n",
    "\t\n",
    "\t# Dimensions (batchsize, X, Y, Z, channles)\n",
    "\treturn images, sparse_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The actual Neural Netowrk Inference Model\n",
    "\n",
    "Intro to convolutional neural nets in Tensorflow:\n",
    "    - [Tensorflow and deep learning - without a PhD by Martin Görner](https://www.youtube.com/watch?v=vq2nnJ4g6N0)\n",
    "\n",
    "3D operations used (everything else is the same as 2D heart-labeling example):\n",
    "\n",
    " - Convolution layer (https://www.tensorflow.org/api_docs/python/tf/nn/conv3d)\n",
    "   - `tf.nn.conv3d(input, filter, strides, padding, name=None)`\n",
    "     - input shape: `[batch, depth, height, width, in_channels]`\n",
    "     - filter shape: `[filter_depth, filter_height, filter_width, in_channels, out_channels]`\n",
    "     - strides shape `[1, ?, ?, ?, 1]` (first/last dim must be 1)\n",
    " - Pool layer (https://www.tensorflow.org/api_docs/python/tf/nn/max_pool3d)\n",
    "   - `tf.nn.max_pool3d(input, ksize, strides, padding, name=None)`\n",
    "     - input shape: `[batch, depth, height, width, channels]`\n",
    "     - ksize: The size of the window for each dimension of the input tensor. \n",
    "       - Must have ksize[0] = ksize[4] = 1\n",
    "       - strides shape [1, ?, ?, ?, 1]\n",
    " - Deconvolution layer https://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose\n",
    "\t- `tf.nn.conv3d_transpose(value, filter, output_shape, strides, padding='SAME', name=None)`\n",
    "         - value: A 5-D Tensor of type float and shape `[batch, depth, height, width, in_channels]`\n",
    "         - filter: A 5-D Tensor with the same type as value and shape `[depth, height, width, output_channels, in_channels]`. \n",
    "           - filter's in_channels dimension must match that of value.\n",
    "         - output_shape: A 1-D Tensor representing the output shape of the deconvolution op.\n",
    "         - strides: A list of ints. The stride of the sliding window for each dimension of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\t    \n",
    "\tprint_tensor_shape( images, 'images shape inference' )\n",
    "\twith tf.name_scope('Conv1'):\n",
    "\t\tW_conv1 = tf.Variable(tf.truncated_normal([3,3,3,1,10],stddev=0.1,dtype=tf.float32),name='W_conv1')\n",
    "\t\tprint_tensor_shape( W_conv1, 'W_conv1 shape')\n",
    "\t\tconv1_op = tf.nn.conv3d(images, W_conv1, strides=[1,2,2,2,1], padding=\"SAME\", name='conv1_op' )\n",
    "\t\tprint_tensor_shape( conv1_op, 'conv1_op shape')\n",
    "\t\trelu1_op = tf.nn.relu( conv1_op, name='relu1_op' )\n",
    "\t\tprint_tensor_shape( relu1_op, 'relu1_op shape')\n",
    "\twith tf.name_scope('Pool1'):\n",
    "\t\tpool1_op = tf.nn.max_pool3d(relu1_op, ksize=[1,3,3,3,1],strides=[1,2,2,2,1], padding='SAME') \n",
    "\t\tprint_tensor_shape( pool1_op, 'pool1_op shape')\n",
    "\twith tf.name_scope('Conv2'):\n",
    "\t\tW_conv2 = tf.Variable(tf.truncated_normal([3,3,3,10,100],stddev=0.1,dtype=tf.float32),name='W_conv2')\n",
    "\t\tprint_tensor_shape( W_conv2, 'W_conv2 shape')\n",
    "\t\tconv2_op = tf.nn.conv3d( pool1_op, W_conv2, strides=[1,2,2,2,1],padding=\"SAME\", name='conv2_op' )\n",
    "\t\tprint_tensor_shape( conv2_op, 'conv2_op shape')\n",
    "\t\trelu2_op = tf.nn.relu( conv2_op, name='relu2_op' )\n",
    "\t\tprint_tensor_shape( relu2_op, 'relu2_op shape')\n",
    "\twith tf.name_scope('Pool2'):\n",
    "\t\tpool2_op = tf.nn.max_pool3d(relu2_op, ksize=[1,3,3,3,1],strides=[1,2,2,2,1], padding='SAME')\n",
    "\t\tprint_tensor_shape( pool2_op, 'pool2_op shape')\n",
    "\twith tf.name_scope('Conv3'):\n",
    "\t\tW_conv3 = tf.Variable(tf.truncated_normal([3,3,3,100,200],stddev=0.1,dtype=tf.float32),name='W_conv3') \n",
    "\t\tprint_tensor_shape( W_conv3, 'W_conv3 shape')\n",
    "\t\tconv3_op = tf.nn.conv3d( pool2_op, W_conv3, strides=[1,2,2,2,1],padding='SAME', name='conv3_op' )\n",
    "\t\tprint_tensor_shape( conv3_op, 'conv3_op shape')\n",
    "\t\trelu3_op = tf.nn.relu( conv3_op, name='relu3_op' )\n",
    "\t\tprint_tensor_shape( relu3_op, 'relu3_op shape')\n",
    "\twith tf.name_scope('Conv4'):\n",
    "\t\tW_conv4 = tf.Variable(tf.truncated_normal([3,3,3,200,200],stddev=0.1,dtype=tf.float32), name='W_conv4')\n",
    "\t\tprint_tensor_shape( W_conv4, 'W_conv4 shape')\n",
    "\t\tconv4_op = tf.nn.conv3d( relu3_op, W_conv4, strides=[1,2,2,2,1],padding='SAME', name='conv4_op' )\n",
    "\t\tprint_tensor_shape( conv4_op, 'conv4_op shape')\n",
    "\t\trelu4_op = tf.nn.relu( conv4_op, name='relu4_op' )\n",
    "\t\tprint_tensor_shape( relu4_op, 'relu4_op shape')\n",
    "\t\t# optional dropout node.  when set to 1.0 nothing is dropped out\n",
    "\t\tdrop_op = tf.nn.dropout( relu4_op, 1.0 )\n",
    "\t\tprint_tensor_shape( drop_op, 'drop_op shape' )\n",
    "\t# Conv layer to generate the 2 score classes\n",
    "\twith tf.name_scope('Score_classes'):\n",
    "\t\tW_score_classes = tf.Variable(tf.truncated_normal([1,1,1,200,2],stddev=0.1,dtype=tf.float32),name='W_score_classes')\n",
    "\t\tprint_tensor_shape( W_score_classes, 'W_score_classes_shape')\n",
    "\t\tscore_classes_conv_op = tf.nn.conv3d( drop_op, W_score_classes,strides=[1,1,1,1,1], padding='SAME', name='score_classes_conv_op')\n",
    "\t\tprint_tensor_shape( score_classes_conv_op,'score_conv_op shape')\n",
    "\t# Upscore the results to 1x256x256x256x2 image\n",
    "\twith tf.name_scope('Upscore'):\n",
    "\t\tW_upscore = tf.Variable(tf.truncated_normal([31,31,31,2,2],stddev=0.1,dtype=tf.float32),name='W_upscore')\n",
    "\t\tprint_tensor_shape( W_upscore, 'W_upscore shape')\n",
    "#\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[BATCH_SIZE,256,256,256,2],strides=[1,16,16,16,1],padding='SAME',name='upscore_conv_op')\n",
    "\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[BATCH_SIZE,IMG_DIM,IMG_DIM,IMG_DIM,2],strides=[1,64,64,64,1],padding='SAME',name='upscore_conv_op')\n",
    "#\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[1,256,256,256,2],strides=[1,64,64,64,1],padding='SAME',name='upscore_conv_op')\n",
    "\t\tprint_tensor_shape(upscore_conv_op, 'upscore_conv_op shape')\n",
    "\t\n",
    "\treturn upscore_conv_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Helper function to show us tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_tensor_shape(tensor, string):\n",
    "    if __debug__:\n",
    "        print('DEBUG ' + string, tensor.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lets load the tfrecord images and push it through our inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DEBUG images shape inference', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(1)]))\n",
      "('DEBUG W_conv1 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(1), Dimension(10)]))\n",
      "('DEBUG conv1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG relu1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG pool1_op shape', TensorShape([Dimension(2), Dimension(10), Dimension(10), Dimension(10), Dimension(10)]))\n",
      "('DEBUG W_conv2 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(10), Dimension(100)]))\n",
      "('DEBUG conv2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG relu2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG pool2_op shape', TensorShape([Dimension(2), Dimension(3), Dimension(3), Dimension(3), Dimension(100)]))\n",
      "('DEBUG W_conv3 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(100), Dimension(200)]))\n",
      "('DEBUG conv3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG relu3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG W_conv4 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(200), Dimension(200)]))\n",
      "('DEBUG conv4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG relu4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG drop_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG W_score_classes_shape', TensorShape([Dimension(1), Dimension(1), Dimension(1), Dimension(200), Dimension(2)]))\n",
      "('DEBUG score_conv_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(2)]))\n",
      "('DEBUG W_upscore shape', TensorShape([Dimension(31), Dimension(31), Dimension(31), Dimension(2), Dimension(2)]))\n",
      "('DEBUG upscore_conv_op shape', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(2)]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Upscore/upscore_conv_op:0' shape=(2, 40, 40, 40, 2) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = os.path.join(INPUT_DIR,TRAIN_FILE)\n",
    "images, labels = inputs(train=True, batch_size=BATCH_SIZE,num_epochs=NUM_EPOCHS, filename=trainfile)\n",
    "inference(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss function\n",
    "\n",
    "This could use some more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\t    \n",
    "\t# input:  logits: Logits tensor, float - [batch_size, 256, 256, 256, 2].\n",
    "\t# intput: labels: Labels tensor, int8 - [batch_size, 256, 256, 256].\n",
    "\t# output: loss: Loss tensor of type float.\n",
    "\t\n",
    "\tlabels = tf.to_int64(labels)\n",
    "\tprint_tensor_shape( logits, 'logits shape ')\n",
    "\tprint_tensor_shape( labels, 'labels shape ')\n",
    "\t\n",
    "\t# reshape to match args required for the cross entropy function\n",
    "\tlogits_re = tf.reshape( logits, [-1, 2] )\n",
    "\tlabels_re = tf.reshape( labels, [-1] )\n",
    "\t#print_tensor_shape( logits_re, 'logits shape after')\n",
    "\t#print_tensor_shape( labels_re, 'labels shape after')\n",
    "\t\n",
    "\t# call cross entropy with logits\n",
    "\tcross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy')\n",
    "\tprint_tensor_shape( cross_entropy, 'cross_entropy shape ')\n",
    "\t\n",
    "\tloss = tf.reduce_mean(cross_entropy, name='1cnn_cross_entropy_mean')\n",
    "\tprint_tensor_shape( loss, 'loss shape ')\n",
    "\t\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training function\n",
    "\tinput: loss: loss tensor from loss()\n",
    "\tinput: learning_rate: scalar for gradient descent\n",
    "\toutput: train_op the operation for training\n",
    "\t\n",
    "\t    Creates a summarizer to track the loss over time in TensorBoard.\n",
    "\t    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "\t\n",
    "\t    The Op returned by this function is what must be passed to the\n",
    "\t    `sess.run()` call to cause the model to train.\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def training(loss, learning_rate, decay_steps, decay_rate):\n",
    "\t# Add a scalar summary for the snapshot loss.\n",
    "\t#tf.scalar_summary(loss.op.name, loss)\n",
    "\ttf.summary.scalar(loss.op.name, loss)\n",
    "\t\n",
    "\t# Create a variable to track the global step.\n",
    "\tglobal_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\t\n",
    "\t# create learning_decay\n",
    "\tlr = tf.train.exponential_decay( learning_rate,global_step,decay_steps,decay_rate, staircase=True )\n",
    "\t#tf.scalar_summary('1learning_rate', lr )\n",
    "\ttf.summary.scalar('learning_rate', lr )\n",
    "\t\n",
    "\t# Create the gradient descent optimizer with the given learning rate.\n",
    "\t#    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\t\n",
    "\t# Use the optimizer to apply the gradients that minimize the loss\n",
    "\t# (and also increment the global step counter) as a single training step.\n",
    "\tprint_tensor_shape( loss, 'loss shape ')\n",
    "\ttrain_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\t\n",
    "\treturn train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Execute the Training loop (with tensorboard?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\twith tf.Graph().as_default():\n",
    "\t\t# specify the training data file location\n",
    "\t\ttrainfile = os.path.join(INPUT_DIR,TRAIN_FILE)\n",
    "\t\timages, labels = inputs(train=True, batch_size=BATCH_SIZE,num_epochs=NUM_EPOCHS, filename=trainfile)\n",
    "\t\t# run inference on the images\n",
    "\t\tresults = inference(images)\n",
    "\t\t# calculate the loss from the results of inference and the labels\n",
    "\t\tloss = loss_fn(results, labels)\n",
    "\t\t# setup the training operations\n",
    "\t\ttrain_op = training(loss, LEARNING_RATE, DECAY_STEPS, DECAY_RATE)\n",
    "\t\t# setup the summary ops to use TensorBoard\n",
    "\t\tsummary_op = tf.summary.merge_all()\n",
    "\t\t# init to setup the initial values of the weights\n",
    "\t\t#init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())\n",
    "\t\tinit_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "\t\t# setup a saver for saving checkpoints\n",
    "\t\tsaver = tf.train.Saver()\n",
    "\t\t# create the session\n",
    "\t\tsess = tf.Session()\n",
    "\t\t# specify where to write the log files for import to TensorBoard\n",
    "\t\tsummary_writer = tf.summary.FileWriter(CHECKPOINT_DIR,sess.graph)\n",
    "\t\t# initialize the graph\n",
    "\t\tsess.run(init_op)\n",
    "\t\t# setup the coordinato and threadsr.  Used for multiple threads to read data.  \n",
    "\t\t# Not strictly required since we don't have a lot of data but typically \n",
    "\t\t# using multiple threads to read data improves performance\n",
    "\t\tcoord = tf.train.Coordinator()\n",
    "\t\tthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\t\t# loop will continue until we run out of input training cases\n",
    "\t\ttry:\n",
    "\t\t\tstep = 0\n",
    "\t\t\twhile not coord.should_stop():\n",
    "\t\t\t\t# start time and run one training iteration\n",
    "\t\t\t\tstart_time = time.time()\n",
    "\t\t\t\t_, loss_value = sess.run([train_op, loss])\n",
    "\t\t\t\tduration = time.time() - start_time\n",
    "\t\t\t\t\n",
    "\t\t\t\t# print some output periodically\n",
    "\t\t\t\tif step % 100 == 0:\n",
    "\t\t\t\t\tprint('OUTPUT: Step %d: loss = %.3f (%.3f sec)' % (step,loss_value,duration))\n",
    "\t\t\t\t\t# output some data to the log files for tensorboard\n",
    "\t\t\t\t\tsummary_str = sess.run(summary_op)\n",
    "\t\t\t\t\tsummary_writer.add_summary(summary_str, step)\n",
    "\t\t\t\t\tsummary_writer.flush()\n",
    "\t\t\t\t# less frequently output checkpoint files.  Used for evaluating the model\n",
    "\t\t\t\tif step % 1000 == 0:\n",
    "\t\t\t\t\tcheckpoint_path = os.path.join(CHECKPOINT_DIR, 'model.ckpt')\n",
    "\t\t\t\t\tsaver.save(sess, checkpoint_path, global_step=step)\n",
    "\t\t\t\tstep += 1\n",
    "\t\t# quit after we run out of input files to read\n",
    "\t\texcept tf.errors.OutOfRangeError:\n",
    "\t\t\tprint('OUTPUT: Done training for %d epochs, %d steps.' % (NUM_EPOCHS,step))\n",
    "\t\t\tcheckpoint_path = os.path.join(CHECKPOINT_DIR, 'model.ckpt')\n",
    "\t\t\tsaver.save(sess, checkpoint_path, global_step=step)\n",
    "\t\tfinally:\n",
    "\t\t\tcoord.request_stop()\n",
    "\t\t# shut down the threads gracefully\n",
    "\t\tcoord.join(threads)\n",
    "\t\tsess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The Go button\n",
    "\n",
    "You probably want to save all your work before running.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DEBUG images shape inference', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(1)]))\n",
      "('DEBUG W_conv1 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(1), Dimension(10)]))\n",
      "('DEBUG conv1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG relu1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG pool1_op shape', TensorShape([Dimension(2), Dimension(10), Dimension(10), Dimension(10), Dimension(10)]))\n",
      "('DEBUG W_conv2 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(10), Dimension(100)]))\n",
      "('DEBUG conv2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG relu2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG pool2_op shape', TensorShape([Dimension(2), Dimension(3), Dimension(3), Dimension(3), Dimension(100)]))\n",
      "('DEBUG W_conv3 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(100), Dimension(200)]))\n",
      "('DEBUG conv3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG relu3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG W_conv4 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(200), Dimension(200)]))\n",
      "('DEBUG conv4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG relu4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG drop_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG W_score_classes_shape', TensorShape([Dimension(1), Dimension(1), Dimension(1), Dimension(200), Dimension(2)]))\n",
      "('DEBUG score_conv_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(2)]))\n",
      "('DEBUG W_upscore shape', TensorShape([Dimension(31), Dimension(31), Dimension(31), Dimension(2), Dimension(2)]))\n",
      "('DEBUG upscore_conv_op shape', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(2)]))\n",
      "('DEBUG logits shape ', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(2)]))\n",
      "('DEBUG labels shape ', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40)]))\n",
      "('DEBUG cross_entropy shape ', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40)]))\n",
      "('DEBUG loss shape ', TensorShape([]))\n",
      "('DEBUG loss shape ', TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
